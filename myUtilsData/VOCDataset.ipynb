{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOC2012のデータセットを作成する\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class VOCDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    VOC2012のDatasetを作成するクラス。PytorchのDatasetクラスを継承.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    img_list : リスト\n",
    "        画像のパスを格納したリスト\n",
    "    anno_list : リスト\n",
    "        アノテーションへのパスを格納したリスト\n",
    "    phase : 'train' or 'test'<ー'val'の間違い？\n",
    "        学習か訓練かを設定する\n",
    "    transform : object\n",
    "        前処理クラスのインスタンス\n",
    "    transform_anno : object\n",
    "        xmlのアノテーションをリストに変換するインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, img_list, anno_list, phase, transform, transform_anno):\n",
    "        self.img_list = img_list\n",
    "        self.anno_list = anno_list\n",
    "        self.phase = phase # trainもしくはvalを指定。\n",
    "        self.transform = transform #画像の変形\n",
    "        self.transform_anno = transform_anno #アノテーションデータをxmlからリストへ\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''画像の枚数を返す'''\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        前処理した画像のテンソル形式のデータとアノテーションを取得\n",
    "        '''\n",
    "        im, gt, h, w = self.pull_item(index)\n",
    "        return im, gt\n",
    "    \n",
    "    def pull_item(self, index):\n",
    "        '''\n",
    "        前処理をした画像のテンソル形式のデータ、アノテーション、画像の高さ、幅を取得する\n",
    "        '''\n",
    "        #1.画像の読み込み\n",
    "        image_file_path = self.img_list[index]\n",
    "        img = cv2.imread(image_file_path) #[高さ][幅][色BGR]\n",
    "        height, width, channels = img.shape #画像のサイズを取得\n",
    "        \n",
    "        #2.xml形式のアノテーション情報をリストに\n",
    "        anno_file_path = self.anno_list[index]\n",
    "        anno_list = self.transform_anno(anno_file_path, width, height)\n",
    "        \n",
    "        #3.前処理の実施\n",
    "        img, boxes, labels = self.transform(\n",
    "            img, self.phase, anno_list[:, :4], anno_list[:, 4])\n",
    "        \n",
    "        #色チャネルの順番がBGRになっているので、RGBに順番変更\n",
    "        #さらに、(高さ、幅、色チャネル)の順を(色チャネル、高さ、幅)に変換\n",
    "        img = torch.from_numpy(img[:, :, (2, 1, 0)]).permute(2,0,1)\n",
    "        \n",
    "        #BBoxとラベルをセットにしたnp.arrayを作成、変数名gtはground truth(答え)の略称\n",
    "        gt = np.hstack((boxes, np.expand_dims(labels, axis=1)))\n",
    "        \n",
    "        return img, gt, height, width\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[   0.9417,    6.1650,   11.1283,  ...,  -22.9083,  -13.2200,\n",
       "             -9.4033],\n",
       "          [   6.4367,    9.6600,   13.8283,  ...,  -21.4433,  -18.6500,\n",
       "            -18.2033],\n",
       "          [  10.8833,   13.5500,   16.7000,  ...,  -20.9917,  -24.5250,\n",
       "            -25.1917],\n",
       "          ...,\n",
       "          [ -23.9500,  -14.9000,   -1.7583,  ..., -108.6083, -111.0000,\n",
       "           -117.8083],\n",
       "          [ -28.2817,  -20.1750,   -5.5633,  ..., -104.9933, -111.8350,\n",
       "           -119.0000],\n",
       "          [ -20.4767,  -21.0000,  -12.6333,  ..., -107.1683, -115.7800,\n",
       "           -117.1100]],\n",
       " \n",
       "         [[  25.9417,   30.1650,   35.1283,  ...,  -18.0767,  -14.7250,\n",
       "            -11.8533],\n",
       "          [  31.4367,   33.6600,   37.8283,  ...,  -13.5017,  -10.8250,\n",
       "            -10.3783],\n",
       "          [  35.7917,   37.5500,   40.7000,  ...,  -11.8417,  -13.0750,\n",
       "            -14.0167],\n",
       "          ...,\n",
       "          [  -1.9500,    7.1000,   20.2417,  ..., -101.9083, -102.0000,\n",
       "           -109.7167],\n",
       "          [  -6.2817,    1.8250,   16.4367,  ..., -100.0517, -103.6700,\n",
       "           -111.0000],\n",
       "          [   1.5233,    1.0000,    9.3667,  ..., -102.5017, -107.7800,\n",
       "           -109.1100]],\n",
       " \n",
       "         [[  45.2750,   55.1650,   62.1283,  ...,   12.8500,   22.0550,\n",
       "             27.8167],\n",
       "          [  50.8800,   58.3300,   64.4983,  ...,   15.8350,   21.5150,\n",
       "             22.7967],\n",
       "          [  56.0667,   60.5500,   65.1500,  ...,   15.6417,   14.8250,\n",
       "             14.7083],\n",
       "          ...,\n",
       "          [  36.7167,   43.1000,   56.2417,  ...,  -94.7583,  -96.0000,\n",
       "           -101.9000],\n",
       "          [  32.3850,   37.8250,   52.4367,  ...,  -92.1617,  -96.0000,\n",
       "           -101.8867],\n",
       "          [  40.1900,   37.0000,   45.3667,  ...,  -94.5017,  -99.7800,\n",
       "            -99.1467]]]),\n",
       " array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
       "        [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#動作確認\n",
    "from make_datapath_list import make_datapath_list\n",
    "from Anno_xml2list import Anno_xml2list\n",
    "from DataTransform import DataTransform\n",
    "\n",
    "color_mean = (104, 117, 123) #(BGR)の色の平均値\n",
    "input_size = 300  #画像のサイズを300*300にする\n",
    "\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform = DataTransform(input_size, color_mean), transform_anno = Anno_xml2list(voc_classes))\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform = DataTransform(input_size, color_mean), transform_anno = Anno_xml2list(voc_classes))\n",
    "\n",
    "#データの取り出し例\n",
    "val_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

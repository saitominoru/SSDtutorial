{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import numpy as np\n",
    "import cv2\n",
    "from make_datapath_list import make_datapath_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#「XML形式のアノテーション」を、リスト形式に変換するクラス\n",
    "class Anno_xml2list(object):\n",
    "    \"\"\"\n",
    "    １枚の画像に対する「XML形式のアノテーションデータ」を、画像サイズで規格化してから\n",
    "    リストに変換する\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes : リスト\n",
    "        VOCのクラス名を格納したリスト\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        \n",
    "        self.classes = classes\n",
    "        \n",
    "    def __call__(self, xml_path, width, height):\n",
    "        \"\"\"\n",
    "        １枚の画像に対する「XML形式のアノテーションデータ」を、画像サイズで規格化して\n",
    "        からリスト形式に変換する\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        xml_path : str\n",
    "            xmlファイルへのパス\n",
    "        width    : int\n",
    "            対象画像の幅\n",
    "        height   : int\n",
    "            対象画像の高さ\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ret : [[xmin, ymin, xmax, ymax, label_ind], ... ]\n",
    "            物体のアノテーションデータを格納したリスト。画像内に存在する物体数の分だけ\n",
    "            要素を持つ。\n",
    "        \"\"\"\n",
    "        \n",
    "        #画像内のすべての物体のアノテーションをこのリストに格納\n",
    "        ret = []\n",
    "        \n",
    "        #xmlファイルを読み込む\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "        \n",
    "        #画像内にある物体('object')の数だけループする\n",
    "        for obj in xml.iter('object'):\n",
    "            \n",
    "            #アノテーションで検知がdifficultに設定されているものは除外\n",
    "            difficult = int(obj.find('difficult').text)\n",
    "            if difficult == 1:\n",
    "                continue\n",
    "                \n",
    "            #１つの物体に対するアノテーションが格納されているリスト\n",
    "            bndbox = []\n",
    "            \n",
    "            name = obj.find('name').text.lower().strip() #物体名\n",
    "            print(name)\n",
    "            bbox = obj.find('bndbox')  #バウンディングボックスの情報\n",
    "            \n",
    "            #アノテーションのxmin,ymin,xmax,ymaxを取得して0~1に正規化\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "            \n",
    "            for pt in (pts):\n",
    "                #VOCは原点が(1,1)なので１を引き算して(0,0)に\n",
    "                cur_pixel = int(bbox.find(pt).text) - 1\n",
    "                \n",
    "                #幅、高さで規格化\n",
    "                if pt=='xmin' or pt=='xmax':  #x方向の時は幅で割り算\n",
    "                    cur_pixel /= width\n",
    "                else: #y方向の時は高さで割り算\n",
    "                    cur_pixel /= height\n",
    "                    \n",
    "                bndbox.append(cur_pixel)\n",
    "                \n",
    "            #アノテーションのクラス名のインデックスを取得して追加\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(label_idx)\n",
    "            \n",
    "            #retに[xmin,ymin.xmax,ymax,label_ind]を足す\n",
    "            ret += [bndbox]\n",
    "            \n",
    "        return np.array(ret)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "person\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
       "       [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#動作確認\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "#画像の読み込み\n",
    "ind = 1\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list,train_anno_list,val_img_list,val_anno_list = make_datapath_list(rootpath)\n",
    "image_file_path = val_img_list[ind]\n",
    "img = cv2.imread(image_file_path) #[高さ][幅][色BGR]\n",
    "height, width, channels = img.shape #画像のサイズを取得\n",
    "\n",
    "#アノテーションをリストで表示 __call__が呼びだされている\n",
    "transform_anno(val_anno_list[ind],width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
